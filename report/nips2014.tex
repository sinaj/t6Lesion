\documentclass{article} % For LaTeX2e
\usepackage{nips14submit_e,times}
\usepackage{hyperref}
\usepackage{url}
%\documentstyle[nips14submit_09,times,art10]{article} % For LaTeX 2.09
\usepackage{graphicx}              % to include figures
\usepackage{epstopdf}
\usepackage{amsmath}               % great math stuff
\usepackage{amsfonts}              % for blackboard bold, etc
\usepackage{amsthm}                % better theorem environments

\usepackage{notoccite}
\usepackage[numbers,sort&compress]{natbib}



\title{Multiple Sclerosis Lesion Segmentation in MRI Images }

\author{
Gautham Vasan \\
Department of Computing Science\\
University of Alberta\\
Edmonton, T6E2H2 \\
\texttt{vasan@ualberta.ca} \\
\And
Jared Rewerts \\
Department of Computer Engineering \\
University of Alberta \\Edmonton, T6E2H2 \\
\texttt{rewerts@ualberta.ca} \\
\And
Megha Panda \\
Department of Computing Science\\
University of Alberta \\Edmonton, T6E2H2 \\
\texttt{meghaanu@ualberta.ca} \\
\texttt{email} \\
\And
Parisa Mohebbi \\
Department of Computing Science \\
University of Alberta \\Edmonton, T6E2H2 \\
\texttt{mohebbi@ualberta.ca} \\
\And
Reza Sobhannejad \\
Department of Computing Science \\
University of Alberta \\Edmonton, T6E2H2 \\
\texttt{sobhanne@ualberta.ca} \\
\And
Sina Jalali  \\
Department of Computing Science \\
University of Alberta \\Edmonton, T6E2H2 \\
\texttt{jalali1@ualberta.ca} \\
}

% The \author macro works with any number of authors. There are two commands
% used to separate the names and addresses of multiple authors: \And and \AND.
%
% Using \And between authors leaves it to \LaTeX{} to determine where to break
% the lines. Using \AND forces a linebreak at that point. So, if \LaTeX{}
% puts 3 of 4 authors names on the first line, and the last on the second
% line, try using \AND instead of \And before the third author name.

\newcommand{\fix}{\marginpar{FIX}}
\newcommand{\new}{\marginpar{NEW}}

\nipsfinalcopy % Uncomment for camera-ready version

\begin{document}


\maketitle
% Abstract
\begin{abstract}
Medical Imaging is an emerging field that can help workload for medical professionals and increase outcomes for afflicted individuals. Our focus is on comparing classification techniques for Multiple Sclerosis lesions in order to find the most successful techniques. We also attempt to combine some techniques to improve detection success. Our results confirm the standard that Random Forest typically provides the best results, but that there are other options useful in segmenting lesions. Interestingly, Random Forest also tends to classify quicker than other algorithms, particularly when compared to SVM. This makes it the most practical in terms of accuracy and speed. 
\end{abstract}

%---------------------------------------- Introduction-------------------------------------------%
\section{Introduction}
Multiple Sclerosis is a debilitating disease that affects the brain and spinal cord. Technically, MS is an autoimmune disease; the immune system attacks parts of the body, in this case, the protective covering of nerve fibers. If occurrences are bad enough, the nerves can build up scar tissue, which impedes nerve conduction. This scar tissue is what we refer to as lesions. 

One of the most shocking aspects of Multiple Sclerosis is that it primarily affects individuals between the ages of 15 and 40. Women are also twice as likely to be affected by MS. Early detection is key to managing symptoms and controlling disease outcomes. Affected individuals can use exercise, cool temperatures and a balanced diet to help treat symptoms.

To detect Multiple Sclerosis lesions, scans are made of patient brains. Medical professionals analyze these scans, looking for signs of MS. These manual segmentation techniques have several drawbacks, not least among them the time input required by the medical professionals. Manual segmentation also has a high rate of error; only 70\% of lesions are properly detected [CITATION NEEDED]. Automatic segmentation techniques hope to improve these. 

One of the main challenges of automatic segmentation is the low lesion volume in patient brain matter. Typically, only a small percentage of the patients brain has lesions, which can make detecting them difficult. This also poses a problem when gathering positive examples of the lesion. The positive to negative ratio is much lower than in many other segmentation problem spaces. Further, since most patients have very little lesion tissue, over classification can be a problem with automated segmentation. If a healthy brain is scanned and processed, ideally, we would show no lesions. In practice, this is can be very difficult.

\subsection{Related Work}
Segmentation of Lesions in MRI images is an active area of research. The 3 main objectives are: 
\begin{enumerate}
  \item Extracting features that can differentiate healthy tissues from scar tissues, 
  \item Selecting the most relevant features that help achieve the task, and
  \item Improving the performance of the classification.
\end{enumerate} 

\subsubsection{Review of Segmentation Methods}
In MS lesion segmentation, the typical features are the intensity of each voxel in different modality images. Additionally, some methods like  \cite{commowick2009continuous}, combined K-NN based on intensities with a template-driven segmentation method to reduce false positives. Others like the method presented in \cite{zijdenbos2002automatic} used the probability of a voxel belonging to tissue class with help of an atlas. Intensity of the six neighbor voxels can be added to feature vector of a point which has been used with an ANN in \cite{younis2007ms}. In \cite{kroon2008multiple}, they used up to 255 features derived from applying different filters on images, and then with the help of principal component analysis (PCA), data is transformed to new orthogonal coordinates so the first column covers the greatest variance between data; hence, a simple thresholding on the first component of PCA can classify lesions. In \cite{geremia2011spatial}, random decision forest (RDF) is used with local (like intensity) and context-rich (will be discussed later) features. RDF has the advantage of automatically selecting the best features over other methods.

\subsubsection{ Exploring Combinations [PLEASE GIVE YOUR COMMENTS ON THIS PART] }
Lots of methods have been employed for lesion segmentation as mentioned before but no valid comparison is done to measure performance of different classifiers using different features. In this project we aim to compare various algorithm's efficiencies on the same data and feature sets to explore their properties in  lesion segmentation. We use Support Vector Machine (SVM), Neural Networks, K-Nearest Neighbors, Random Forest, Markov Random Field, and Logistic Regression as classifiers. For features, we use Haar-Like, image filters, LM filters, entropy, gaussian based, and atlas. In a broad sense, we tried to extract all possible features to see how the well-known classifiers operate based on them.

%------------------------------------------- Features ----------------------------------------------%
\section{Feature Detection}
%What is feature extraction? Why is it important? Reasons for using the particular features
Image analysis aims at reducing information to a subset that is relevant to the task in hand. Information reduction often happens gradually with information being reduced until the desired result is extracted from the data. \cite{toennies2012guide} The first level of reduction computes local features that
are assumed to pertain to objects of interest. 
\subsection{Context (Haar-Like Features)}

\subsection{Image Filters}

\subsubsection{Leung-Malik(LM) Filter Bank}

\subsection{Entropy \& Gaussian based Features)}

\subsection{Atlas Features}

All the features need to explained briefly with good images.

%------------------------------------------------ Classifiers ------------------------------------------%
\section{Classifiers}

Reasons for using each classification method. Brief description about them. No need for images here I guess.  

\subsection{Support Vector Machines}

\subsection{Neural Networks}

\subsection{k-Nearest Neighbours}

\subsection{Random Forests}

\subsection{Markov Random Fields}
The basic principal of markov random field is treating the input image as a graph in which each voxel is a node and neighboring voxels are connected. In the case of foreground segmentation, two spacial nodes of foreground and background are added to the graph and edges between voxels and each of these two nodes have a weight equal to the probability of that voxel belongs to eighther foreground or background. Aim of the algorithm is using a graph-cut to divide graph into two classes subject to the combination of cutted edges is minimum.The advantage of this method is considering neighbors probabilities as a feature.
In this project, we trained a random forest (which claimed to be the best algorithm for lesion segmentation) and used it to obtain initial probabilities of each voxel belonging to lesion. Then, MRF is applied based on the constructed graph.

\subsection{Logistic Regression}

%-----------------------------------Experiment Design -------------------------------------------------------%
\section{Experiment Design}
Pipeline Diagram is required here

\subsection{Validation Measures}
False Positive, false negative, etc. Why Dice is preferred?
\subsubsection{Dice Score}
\subsubsection{Accuracy}
\subsubsection{Sensitivity}
\subsubsection{Detections}

\subsection{Training and Test Data}
BrainWeb and Miccai Challenge Data. Explain how sampling is done on data to train the classifier. 

% --------------------------------------- Results ----------------------------------------------------%
\section{Results}
Lots of Images! Table with comparative results. Explanation for why we get these results. 

\subsection{State of the art results}
Brief description of the benchmark

\subsection{Discussion}
Detailed analysis of the results we get from different results

%-------------------------------------- Conclusion ------------------------------------------%
\section{Conclusion}

% ---------------------------------------- Acknowledgements ----------------------------------%
\section{Acknowledgements}

%------------------------------------------- References ----------------------------------------%
\section{References}

\bibliography{bibliography}
\bibliographystyle{plain}

\end{document}
